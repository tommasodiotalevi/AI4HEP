{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0744c83-2763-4b1b-a8f2-0a21677bbc40",
   "metadata": {},
   "source": [
    "# Transform the Keras model into a HLS project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493117b-5a18-4384-8033-b5919bac7d62",
   "metadata": {},
   "source": [
    "Import libraries, including hls4ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa57fbbe-9b42-44cb-8aee-ace4c8ef0149",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from qkeras.utils import load_qmodel\n",
    "import hls4ml\n",
    "import json\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from utils.utils import preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea6dd2-6dd1-4288-81c2-3f2181fc1585",
   "metadata": {},
   "source": [
    "Define the project name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b987c2-f3f1-462c-8182-b8de62873259",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"QKeras_Model_60_50_30_40_15\"\n",
    "outputname =\"QKeras_Model_60_50_30_40_15_HLS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5994c50b-a6a4-49c8-9afd-0eb6c08b4e6f",
   "metadata": {},
   "source": [
    "Load the model that was created in the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c747e1da-636e-4739-84bf-9fa44cb56047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_qmodel('model.h5')\n",
    "\n",
    "X_test,Y_test = preproc(test=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52dc197e-3f08-4e71-afd9-a0d3cddcb68f",
   "metadata": {},
   "source": [
    "Now we have to config hls4ml, with some initial options:\n",
    "- **Granularity**: sets the level of granularity to the given options. `name` means that a per-layer configuration is given, generating separate config keys for highly specific tweaks;\n",
    "- **Reuse factor**: Defines the level of parallelisation required. A low reuse factor achieves lower latencies and higher throughputs, but uses most resources. An higher reuse factor save resources at the expense of longer latency and lower throughput.\n",
    "![immagine.png](images/reuse_factor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987c7e3-38e7-4108-b5cc-f1129b1047c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating configuration dictionary\n",
    "config = hls4ml.utils.config_from_keras_model(model, granularity='name',default_reuse_factor=1) \n",
    "\n",
    "#Activating tracing (i.e. saving also the results passed between hidden layers)\n",
    "for layer in config['LayerName'].keys():\n",
    "    config['LayerName'][layer]['Trace'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5c0ef-3726-4a9d-ae9c-6bf21646c478",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(config, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed32eb-4e3f-4b63-9902-3fbf36942e60",
   "metadata": {},
   "source": [
    "Now that the configuration dictionary has been created, we can convert the QKeras model created before in a hls4ml-ready model. Here is important to notice that we have to specify the **FPGA hardware**, so that a correct mapping of the device hardware can be made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598053a-cb9e-44c5-846a-e8435daeb368",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model = hls4ml.converters.convert_from_keras_model(model, hls_config=config, output_dir=modelname +'/'+ outputname + '/HLS_Project',fpga_part='xc7z020-1clg400c') ## FPGA Part: PYNQ-Z2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a1fad4-19e1-4512-864f-12c5e2161c2b",
   "metadata": {},
   "source": [
    "Let’s visualise what we created. The model architecture is shown, annotated with the shape and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae60be-68bf-4d9e-82ba-6f3d1f599c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hls4ml.utils.plot_model(hls_model, show_shapes=True, show_precision=True, to_file=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960c70a2-88d3-40fc-882c-fdb0c17fae48",
   "metadata": {},
   "source": [
    "## Compile the model with hls4ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f9592-95d8-42c1-8b19-451ba838d60f",
   "metadata": {},
   "source": [
    "Now we need to check that this model performance is still good. We compile the hls_model, and then use `hls_model.predict` to execute the FPGA firmware with bit-accurate emulation on the CPU. On the other hand, the predictions made by QKeras are computed using `model.predict()` as usual. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1fb8e9-5581-4e60-beb6-9af2e75e12c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.compile()\n",
    "X_test = np.ascontiguousarray(X_test)\n",
    "Y_hls = hls_model.predict(X_test)\n",
    "\n",
    "Y_keras = model.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ec617-f9ef-4ea7-8fad-d9a4f62dfe17",
   "metadata": {},
   "source": [
    "Now let’s see how the performance compares to QKeras, by computing the root mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920364e-9bcb-49eb-92e8-7e16c25fbb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "qkeras_rmse = np.sqrt(mean_squared_error(Y_test, Y_keras))\n",
    "hls_rmse = np.sqrt(mean_squared_error(Y_test, Y_hls))\n",
    "\n",
    "print(\"QKeras  RMSE: {}\".format(qkeras_rmse))\n",
    "print(\"hls4ml RMSE: {}\".format(hls_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7745823a-7e25-4c91-8872-e8a629be6ad5",
   "metadata": {},
   "source": [
    "## Synthesize the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09401ca5-6bf2-4ddf-8529-4fa066ef0c54",
   "metadata": {},
   "source": [
    "New final step would be the synthesis of the model, using the Vivado HLS tool from Xilinx (now part of AMD). The software depends on the hardware used, in our case the **Xilinx PYNQ-Z2 board**:\n",
    "\n",
    "![immagine.png](images/pynq-z2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b4713e-20cc-4d5c-bd0b-f67132d00814",
   "metadata": {},
   "outputs": [],
   "source": [
    "hls_model.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7ef219-ac1a-480b-b591-a7e570a90cfb",
   "metadata": {},
   "source": [
    "This step however will fail (here), because we don't have Vivado HLS installed in the system. This is normal because it requires licenced software that cannot fit in this platform. This step has been done separately and, after creating the actual firmware, we are ready to continue in the FPGA board..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
